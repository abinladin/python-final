{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining - Second Assignment\n",
    "\n",
    "For each question provide an answer in the designated area. Try to be brief and precise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "A binary classifier produced the confusion matrix shown below. Calculate the precision in this case. What is the size of the corpus?\n",
    "\n",
    "![confusion-matrix 1](https://tsourakis.net/tec640/confusion-matrix1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:green;\"><b>Answer:<b><p> summing all of the values together, 10115"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "The three models that are shown below (depicted with the red line) try to separate the data with labels __X__ and __O__ . Which one do you think generalizes<sup>*</sup> better (left/middle/right)? Explain your answer.\n",
    "\n",
    "![models](https://tsourakis.net/tec640/models.png)\n",
    "\n",
    "<sup>*</sup>Generalization is the ability of a model to classify correctly unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:green;\"><b>Answer:<b><p> The middle one. left is underfitted and will struggle to perform better than the baseline, right is overfitted and will not generalize well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Based on the images below, which one of the ROC curves produces AUC values greater than 0.5 (left/middle/right)? Explain your answer.\n",
    "\n",
    "![roc 1](https://tsourakis.net/tec640/roc1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:green;\"><b>Answer:<b></p> right. the AUC measures the area under the ROC curve, and the middle will have an auc of 0.5 \n",
    "\n",
    "\n",
    "$$\\frac{1}{2} fp \\cdot tp = 0.5$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "The image below shows a special type for word representation. How is it called and what can we deduce from this image?\n",
    "\n",
    "![representation](https://tsourakis.net/tec640/representation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:green;\"><b>Answer:<b><p>  This is a word embedding, specifically word2vec. we can deduce that countries are mapped to their capital cities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Among the three options below, what is the best option on how to split our data (left/middle/right)? Elaborate on your answer.\n",
    "\n",
    "![split](https://tsourakis.net/tec640/split.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:green;\"><b>Answer:<b><p> left. middle is wrong because you need to ttrain on as much data as possible, and right is wrong because you need a yardstick to measure performance against."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "The following images show the confusion matrices for two classification models. Which model works better and why (left or right)?\n",
    "\n",
    "![confusion-matrix 2](https://tsourakis.net/tec640/confusion-matrix2.png)\n",
    "![confusion-matrix 3](https://tsourakis.net/tec640/confusion-matrix3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:green;\"><b>Answer:<b><p> The bottom (second) one works better because there are fewer miscategorized inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "\n",
    "Based on the confusion matrix below, what can you say about the relation between labels __D__ and __C__?\n",
    "\n",
    "![confusion-matrix 2](https://tsourakis.net/tec640/confusion-matrix2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:green;\"><b>Answer:<b><p> The model correctly classifies C as not D, but struggles more to classify D as not C. in terms of features, D may be a superset of C, and may consider some more pronounced features of D as outliers of C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "\n",
    "After performing Exploratory Data Analysis (EDA) on our data we get the pie chart shown below. It represents the sentiment found in the texts of the corpus.\n",
    "Based on the chart, can you identify any issue, and if yes, how can it be resolved?\n",
    "\n",
    "![pie-chart](https://tsourakis.net/tec640/pie-chart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:green;\"><b>Answer:<b><p>  The issue is that the classes are not equally distributed. An easy solution if you have a lot of data is to sample the size of happy/joyful from each class, so that they are evenly distributed. Alternatively you can train your model on the dataset as-is and compare its performance to a baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9\n",
    "\n",
    "Suppose that you create two classification models that can predict cancer based on patients' data. Which metric is more appropriate in order to compare the two models? Precision or recall? Explain your answer.\n",
    "\n",
    "__Hint__: Think of the type of errors used by each metric and which error should be avoided for cancer detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:green;\"><b>Answer:<b><p> recall. It's better to get a false positive and get it checked out than to get a false negative and ignore a cancer case you may have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10\n",
    "\n",
    "Using the KNN algorithm what is the label of the sample with the question mark when k=9?\n",
    "\n",
    "![knn](https://tsourakis.net/tec640/knn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:green;\"><b>Answer:<b><p> circle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 11\n",
    "\n",
    "Based on the ROC curves below which classification algorithms combination works better? Explain your answer.\n",
    "\n",
    "![roc 2](https://tsourakis.net/tec640/roc2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:green;\"><b>Answer:<b><p> both the \"svm + Naive Bayes ROC\" and the \"SVM ROC\" have the same AOC. However, the SVM ROC performs better and earlier with respect to the false positive rate, and so it is slightly superior "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 12\n",
    "\n",
    "How do we call the type of learning where we use labeled examples during training (see the image below)?\n",
    "\n",
    "![training](https://tsourakis.net/tec640/training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:green;\"><b>Answer:<b><p> supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 13\n",
    "\n",
    "In the code shown below, how do we call _kernel_, _C_ and _gamma_?\n",
    "\n",
    "``from sklearn import svm``\n",
    "\n",
    "``svm_classifier = svm.SVC(kernel=\"rbf\", C=1.0, gamma=1.0)``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:green;\"><b>Answer:<b><p>  hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 14\n",
    "\n",
    "Based on the figure below, how do we call the transformation of the words in the second column to the words in the third one?\n",
    "\n",
    "![words](https://tsourakis.net/tec640/words.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:green;\"><b>Answer:<b><p> lemmatization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 15\n",
    "\n",
    "You use a dataset with 10,000 labeled examples to train a classification algorithm. Then, during the inference phase, you use the same examples to calculate the performance of the generated model. The latter gives you 99% accuracy. Can you know launch your model in the production system? Explain your answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:green;\"><b>Answer:<b><p> No, because the data is likely overfitted, and to get a more representative idea of how it should perform, it should be tested on a test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 16\n",
    "\n",
    "Consider the vectors shown in the image below _A=(4, 4, 4)_, _B=(1, 7, 5)_ and _C=(-5, 5, 1)_. Which is the method that can tell us which pair of vectors is more similar?\n",
    "\n",
    "![vectors](https://tsourakis.net/tec640/vectors.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:green;\"><b>Answer:<b><p> law of cosinality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 17\n",
    "\n",
    "How can we create plots like the one shown in the figure below in Python and how are they called?\n",
    "\n",
    "![nlp](https://tsourakis.net/tec640/nlp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:green;\"><b>Answer:<b><p> they are called word clouds, and you can use the WordCloud module to generate them and show the image with plt.imshow(wc.generate(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 18\n",
    "\n",
    "\n",
    "You are managing a team of data scientists that produced the following table after testing various machine learning algorithms.\n",
    "It is your job to decide which algorithm to use for the problem under study. Which one would you choose and why?\n",
    "\n",
    "![results](https://tsourakis.net/tec640/results.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:green;\"><b>Answer:<b><p> Random forest, because it has the largest F score, presicion, and recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 19\n",
    "\n",
    "Suppose that your machine learning problem consists of a large set of features with similar characteristics. What is the technique to identify and decrease the number of features for this specific problem? Name one example of this technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:green;\"><b>Answer:<b><p> Dimensionality reduction techniques such as PCA and LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 20\n",
    "\n",
    "In most machine learning problems, you need to create your own dataset. For example, suppose you want to train a model to identify where to add extra armor to a fighting plane. After each battle, you examine all the aircraft that managed to return back to the base despite being damaged. The red dots in the image below represent the hits you have counted from those aircraft. Try to think where you should add the extra armor by looking at the figure. Can you identify the problem of creating your dataset like this?\n",
    "\n",
    "\n",
    "![plane](https://tsourakis.net/tec640/plane.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:green;\"><b>Answer:<b><p> The issue is survivorship bias - I am looking at planes that survived the fighting. In other words, it is alright to leave the areas where red dots are found unarmored, and instead I should armore the blank areas, because planes shot there were destroyed in the field."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "8f1e200aa4e9598f1b1017d8bb6526388dc3fae44f5def43455ba665e800f8e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
